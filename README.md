### MPBA (Minimum Perturbation Black-box Attack)
#### This is the code for our paper:<br>
J. Sun, H. Yu, and J. Zhao, "Black-box ℓ1 and ℓ2 Adversarial Attack Based on
Genetic Algorithm", In Proc. 6th IEEE International Conference on Artificial Intelligence Testing,
Testing and Evaluation of Large Language Models Workshop, Shanghai, China, July 15-18, 2024 

#### This repository contains:<br>
1). the implementation of our proposed black-box L1 adversarial attack based on genetic algorithm;<br>
2). the code for reproducing our experiment;<br>
3). our experimental results.<br>
#### Requirements
- pytorch
- torchvision
- numpy
- matplotlib
- torchattacks https://github.com/Harry24k/adversarial-attacks-pytorch
- robustbench https://github.com/RobustBench/robustbench
- Adversarial-library https://github.com/jeromerony/adversarial-library


Adversarial examples generated by the proposed method:
<p align="center">
    <img src="GA_AE_mnist_L1.png" width="450">
</p>
<p align="center">
<b>Figure.</b> L1 adversarial examples generated on MNIST. (1st row: original images; 2nd-4th row: adversarial examples generated on three models.)
</p>

Our experiment is based on Python3.11. Only models for MNIST are in the repository. Models for CIFAR and ImageNet will be downloaded automatically by robustbench package. MNIST and CIFAR datasets would also be downloaded automatically and the images used for ImageNet(ILSVRC2012) are the first 100 in validation set. To reproduce the results presented:

- Results for MNIST in Table 2  can be generated by running  ```python experiment_MNIST_genetic.py```.<br>
- Results for CIFAR10 in Table 3 can be generated by running  ```python experiment_CIFAR_genetic.py```.<br>
- Results for ImageNet in Table 4 can be generated by running  ```python experiment_imagenet_genetic.py```.<br>
- Running results will be stored in ```./result```